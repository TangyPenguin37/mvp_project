{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> This script and the dependencies in it require the use of a **CUDA-enabled GPU** with appropriate drivers."
      ],
      "metadata": {
        "id": "lNXfgWlamOTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "***Note:*** *This may take up to **15 minutes** on first run.*"
      ],
      "metadata": {
        "id": "M6SljU4lnEfZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjmzwR15VxSe"
      },
      "source": [
        "## Define Parameters\n",
        "Define a URL from which to download the input video, along with a filename under which to save it.\n",
        "\n",
        "Alternatively, a video can be manually uploaded by updating the `FILENAME` parameter accordingly and commenting out the `!wget ...` line.\n",
        "\n",
        "Some example videos can be found in the inputs folder on the [GitHub repository](https://github.com/TangyPenguin37/mvp_project)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://videos.pexels.com/video-files/29460515/12682115_2160_3840_30fps.mp4\"\n",
        "FILENAME = \"shipwreck.mp4\"                    # Choose a filename under which to save the video, or open an existing file\n",
        "PROMPT = \"make the ship into a pirate ship\"   # Choose the prompt with which to edit the model\n",
        "ITERATIVE = False                             # Choose whether to use the iterative pipeline or not\n",
        "ITERATIONS = 4                                # Choose the number of iterations, if using the iterative pipeline\n",
        "BATCH_SIZE = 16                               # Choose a batch size for InstructPix2Pix - default: 16\n",
        "FRAMES = 200                                  # Choose (approximately) how many frames to extract from the input video\n",
        "RESOLUTION = (1280, 720)                      # Choose a resolution for the images from FFmpeg to be resized to - lower values decrease quality but also decrease editing and training time."
      ],
      "metadata": {
        "id": "p41fMBgXCGa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt3IT8V1tUtl"
      },
      "outputs": [],
      "source": [
        "# Download the given URL - comment this line out if you wish to use a manually uploaded video.\n",
        "!wget $URL -O $FILENAME"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and install dependencies\n",
        "\n",
        "Clone GitHub repository and install all the necessary dependencies.\n",
        "\n",
        "-----\n",
        "\n",
        "**Note:** The COLMAP executable in this repository is built specifically for the **T4 GPU in Google Colab**, so as to not require rebuilding with each run. If you are using a different GPU, even within Google Colab, our script may fail. To remedy this, COLMAP must be built from source on the desired GPU architecture and added to PATH in place of the COLMAP file used here. *Instructions on building COLMAP can be found [here](https://colmap.github.io/install.html).*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7LriGy7Sm2T4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1WvyCqMs9MH"
      },
      "outputs": [],
      "source": [
        "# Remove the Google Colab sample data directory, if it exists\n",
        "!rm -rf ./sample_data\n",
        "\n",
        "# Clone the GitHub repository\n",
        "!echo -e \"\\e[34mCloning repository...\\e[0m\" && GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/TangyPenguin37/mvp_project -q --recurse-submodules && echo -e \"\\e[34mCloned repository!\\e[0m\"\n",
        "\n",
        "# Download and install the necessary dependencies for the Gaussian Splatting script using pip\n",
        "!echo -e \"\\e[34mInstalling dependencies for Gaussian Splatting\\e[0m\" && pip install -q -r ./mvp_project/dependencies/requirements.txt && echo -e \"\\e[34mInstalled dependencies for Gaussian Splatting!\\e[0m\"\n",
        "\n",
        "# Download and install the necessary dependencies for COLMAP using apt-get\n",
        "!echo -e \"\\e[34mInstalling dependencies for COLMAP\\e[0m\" && xargs -a ./mvp_project/dependencies/apt-get.txt apt-get -qq install && echo -e \"\\e[34mInstalled dependencies for COLMAP!\\e[0m\"\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import gc\n",
        "import logging\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
        "\n",
        "# Set executable permissions for COLMAP and add it to PATH\n",
        "!chmod +x /content/mvp_project/colmap/src/colmap/exe/colmap\n",
        "os.environ[\"PATH\"] += \":/content/mvp_project/colmap/src/colmap/exe\"\n",
        "\n",
        "# Set up the InstructPix2Pix model\n",
        "!echo -e \"\\e[34mSetting up InstructPix2Pix model...\\e[0m\"\n",
        "IP2P = StableDiffusionInstructPix2PixPipeline.from_pretrained(\"timbrooks/instruct-pix2pix\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "!echo -e \"\\e[34mSetup completed!\\e[0m\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H49XnwMvVw1j"
      },
      "source": [
        "# Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the video into frames"
      ],
      "metadata": {
        "id": "pVjmpco-N-Eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJrKgb3kFENb"
      },
      "outputs": [],
      "source": [
        "# Define the folder in which files are placed. The default is the filename without the file extension.\n",
        "FOLDER = Path(FILENAME).stem\n",
        "\n",
        "# Create the input folder to store the video frames\n",
        "!rm -rf ./input/$FOLDER\n",
        "!mkdir -p ./input/$FOLDER/input\n",
        "\n",
        "# Extract frames from the video using FFmpeg, getting as close to \"FRAMES\" frames as possible\n",
        "!ffpb -i ./$FILENAME -qscale:v 1 -qmin 1 -vf fps=$(expr $FRAMES / $(printf \"%.0f\\n\" $(ffprobe -i $FILENAME -show_entries format=duration -v quiet -of csv='p=0'))) ./input/$FOLDER/input/%03d.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwzJr8RHVwfU"
      },
      "source": [
        "## Run COLMAP\n",
        "If this section fails, it may be because the version of COLMAP in the GitHub repository is built specifically for the **T4 GPU in Google Colab**. For a different GPU, COLMAP must be rebuilt from source using the instructions [here](https://colmap.github.io/install.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj0kyiM_uMCa"
      },
      "outputs": [],
      "source": [
        "# Define arguments for COLMAP - these can be modified if desired\n",
        "SOURCE = f\"/content/input/{FOLDER}\"\n",
        "CAMERA = \"OPENCV\"\n",
        "COLMAP = \"colmap\"\n",
        "USE_GPU = True\n",
        "\n",
        "use_gpu_arg = str(int(USE_GPU))\n",
        "\n",
        "# Create necessary directories for COLMAP\n",
        "!mkdir -p $SOURCE/distorted/sparse\n",
        "\n",
        "# Run COLMAP feature extractor to find features in each image\n",
        "!$COLMAP feature_extractor \\\n",
        "  --database_path $SOURCE/distorted/database.db \\\n",
        "  --image_path $SOURCE/input \\\n",
        "  --ImageReader.single_camera 1 \\\n",
        "  --ImageReader.camera_model $CAMERA \\\n",
        "  --SiftExtraction.use_gpu $use_gpu_arg\n",
        "\n",
        "# Run COLMAP exhaustive matcher to find matches between images\n",
        "!$COLMAP exhaustive_matcher \\\n",
        "  --database_path $SOURCE/distorted/database.db \\\n",
        "  --SiftMatching.use_gpu $use_gpu_arg\n",
        "\n",
        "# Run COLMAP mapper to create a sparse reconstruction\n",
        "!$COLMAP mapper \\\n",
        "  --database_path $SOURCE/distorted/database.db \\\n",
        "  --image_path $SOURCE/input \\\n",
        "  --output_path $SOURCE/distorted/sparse \\\n",
        "  --Mapper.ba_global_function_tolerance=0.000001\n",
        "\n",
        "# Run COLMAP image undistorter to undistort images\n",
        "!$COLMAP image_undistorter \\\n",
        "  --image_path $SOURCE/input \\\n",
        "  --input_path $SOURCE/distorted/sparse/0 \\\n",
        "  --output_path $SOURCE \\\n",
        "  --output_type COLMAP\n",
        "\n",
        "# Create directory for sparse output\n",
        "!mkdir -p $SOURCE/sparse/0\n",
        "\n",
        "# Move files into this directory\n",
        "for file in os.listdir(f\"{SOURCE}/sparse\"):\n",
        "  if (file != '0'):\n",
        "    shutil.move(\n",
        "      os.path.join(SOURCE, \"sparse\", file),\n",
        "      os.path.join(SOURCE, \"sparse\", \"0\", file),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command to convert .bin COLMAP files to .txt, if desired for a viewer program"
      ],
      "metadata": {
        "id": "lSTKZX_jJfH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !colmap model_converter \\\n",
        "#   --input_path path-to-binary-reconstruction \\\n",
        "#   --output_path path-to-txt-reconstruction \\\n",
        "#   --output_type TXT"
      ],
      "metadata": {
        "id": "e3bDecQLGztt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zx1ffr5QBzb"
      },
      "source": [
        "## Diffusion and Gaussian Splatting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process and edit images in batches\n",
        "def process_images(input_path, output_path, files, batch_size, prompt, resolution):\n",
        "  # Create the output folder for the edited images\n",
        "  !mkdir -p $output_path\n",
        "\n",
        "  # Process images in batches\n",
        "  for i in range(0, len(files), batch_size):\n",
        "    # Clear GPU cache to ensure sufficient memory\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Create a batch of resized images\n",
        "    batch = [Image.open(os.path.join(input_path, file)).resize(resolution) for file in files[i:min(i + batch_size, len(files))]]\n",
        "\n",
        "    # Edit the batch of images using InstructPix2Pix\n",
        "    edited_imgs = (IP2P(prompt=[prompt] * len(batch), image=batch).images)\n",
        "\n",
        "    # Save and close each of the edited images, keeping the original filenames\n",
        "    for j, edited_img in enumerate(edited_imgs):\n",
        "      edited_img.save(os.path.join(output_path, files[i + j]))\n",
        "      edited_img.close()\n",
        "\n",
        "    # Close the original images\n",
        "    for img in batch:\n",
        "      img.close()\n",
        "\n",
        "  # Clear GPU cache\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "# Function to train a Gaussian splatting model and produce renders from it\n",
        "def train_and_render(input_path, output_path, model_path):\n",
        "  # Train Gaussian Splatting model\n",
        "  !python ./mvp_project/submodules/gaussian-splatting/train.py -s $input_path -i $output_path --test_iterations -1 -m $model_path\n",
        "\n",
        "  # Render the output, using the original frames' camera positions\n",
        "  !python ./mvp_project/submodules/gaussian-splatting/render.py -m $model_path\n",
        "\n",
        "# Non-iterative pipeline\n",
        "if not ITERATIVE:\n",
        "\n",
        "  # Define input and output directories\n",
        "  INPUT_DIR = \"images\"\n",
        "  OUTPUT_DIR = \"images_edited\"\n",
        "\n",
        "  input_path = f\"/content/input/{FOLDER}/{INPUT_DIR}\"\n",
        "  output_path = f\"/content/input/{FOLDER}/{OUTPUT_DIR}\"\n",
        "\n",
        "  # Get sorted list of files in the input directory\n",
        "  files = sorted(os.listdir(input_path))\n",
        "\n",
        "  # Process images and save the edited versions\n",
        "  process_images(input_path, output_path, files, BATCH_SIZE, PROMPT, RESOLUTION)\n",
        "\n",
        "  # Train the model and render the output\n",
        "  train_and_render(f\"/content/input/{FOLDER}\", OUTPUT_DIR, f\"/content/output/{FOLDER}/model\")\n",
        "\n",
        "# Iterative pipeline\n",
        "else:\n",
        "\n",
        "  # Define input directory and initial output folder\n",
        "  INPUT_DIR = \"images\"\n",
        "  input_path = f\"/content/input/{FOLDER}/{INPUT_DIR}\"\n",
        "  output_folder = \"images_1\"\n",
        "\n",
        "  # Get sorted list of all files in the input directory\n",
        "  allfiles = sorted(os.listdir(input_path))\n",
        "\n",
        "  # Resize all images to the specified resolution\n",
        "  for file in allfiles:\n",
        "    img = Image.open(os.path.join(input_path, file))\n",
        "    img = img.resize(RESOLUTION)\n",
        "    img.save(os.path.join(input_path, file))\n",
        "    img.close()\n",
        "\n",
        "  # Iterate through as many times as specified\n",
        "  for i in range(ITERATIONS):\n",
        "\n",
        "    # Define the output path for the current iteration\n",
        "    output_path = f\"/content/input/{FOLDER}/{output_folder}\"\n",
        "    shutil.copytree(input_path, output_path)\n",
        "\n",
        "    # Select files for the current iteration\n",
        "    files = allfiles[i::ITERATIONS]\n",
        "\n",
        "    # Process images and save the edited versions\n",
        "    process_images(input_path, output_path, files, BATCH_SIZE, PROMPT, RESOLUTION)\n",
        "\n",
        "    # Train the model and render the output\n",
        "    train_and_render(f\"/content/input/{FOLDER}\", output_folder, f\"/content/output/{FOLDER}/model_{i}\")\n",
        "\n",
        "    # Replace original files with the rendered output\n",
        "    for idx, file in enumerate(sorted(os.listdir(f\"/content/output/{FOLDER}/model_{i}/train/ours_30000/renders\"))):\n",
        "      os.replace(f\"/content/output/{FOLDER}/model_{i}/train/ours_30000/renders/{file}\", f\"/content/input/{FOLDER}/{output_folder}/{allfiles[idx]}\")\n",
        "\n",
        "    # Update input path and output folder for the next iteration\n",
        "    input_path = f\"/content/input/{FOLDER}/{output_folder}\"\n",
        "    output_folder = f\"images_{i+2}\""
      ],
      "metadata": {
        "id": "6B-AKF5Fy8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the final Gaussian splatting model, the model can be viewed on Windows using the SIBR Viewer tool found in our [GitHub repository](https://github.com/TangyPenguin37/mvp_project). Alternatively, there are several online tools such as [this one](https://antimatter15.com/splat/).\n",
        "\n",
        "The Windows viewer also allows the camera positions directly from COLMAP to be passed in, such that the original input video path can be recreated."
      ],
      "metadata": {
        "id": "0cc56j0ABIXN"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}